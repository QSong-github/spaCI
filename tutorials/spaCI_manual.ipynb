{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70bea20",
   "metadata": {},
   "source": [
    "# spaCI manual and tutorial\n",
    "\n",
    "### tutorial\n",
    "  To run spaCI, the input data are shown in the required structure and the data path is assigned in the configure.yml files. Please refer to our preprocess manual [here](https://github.com/QSong-github/spaCI/blob/main/tutorials/tutorial_preprocess.md) for details.\n",
    "  \n",
    "With the data and configuration yaml file, spaCI will output embeddings and predictions in one command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "* bash parameter_tuning.sh
    * python main_yaml.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081d189",
   "metadata": {},
   "source": [
    "### manual\n",
    "  * The following manual shows how spaCI runs step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746bf49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Import python modules\n",
    "2. Load configurations\n",
    "3. Fix seed\n",
    "4. Build dataloader\n",
    "5. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb405989",
   "metadata": {},
   "source": [
    "### 1. Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f88d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "# insert the parent dir into the path\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import yaml\n",
    "from model.dataloader import TripletData\n",
    "from model.model import TripletGraphModel\n",
    "import os\n",
    "import torch.utils.data as Data\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c5de5",
   "metadata": {},
   "source": [
    "### 2. Load configurations\n",
    "The configure.yml defines the model structure and hypter-parameters for training\n",
    "You can also manunally change the configure.yml or generate it using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a46f04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = 'python ../configuration.py --trainroot ../dataset/triplet.csv --testroot ../dataset/test_pairs.csv --predroot \n",
    "../dataset/test_lr_pairs.csv --matrixroot ../dataset/exp_data_LR.csv --adjroot ../dataset/spatial_graph.csv \n",
    "--ymlname ../configure.yml --threshold 0.5'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2ca435",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = '../configure.yml'\n",
    "with open(yaml_file) as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84510171",
   "metadata": {},
   "source": [
    "### 3. Fix seed\n",
    "All seeds are fixed for reproducibility.\n",
    "When using GPUs, it is necessary to fix cuda as follows:\n",
    "```\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "```\n",
    "When using CPU, you may comment these lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ae9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e698392a",
   "metadata": {},
   "source": [
    "### 4. Build dataloader\n",
    "We set up three different modes (mode=0, 1, 2) when building the dataset\n",
    "* mode=1: for training step. spaCI is in training mode.\n",
    "* mode=0: for evaluatation step. Check F1 score on validation set.\n",
    "* mode=2: for prediction step. Save L-R embeddings and output L-R interaction predictions.\n",
    "\n",
    "Note that the output of training(mode=1) returns:\n",
    "* (a, p, n) which refers to the gene triplet anchor, positive and negative pairs\n",
    "* (aid, pid, nid) are the corresponding index in the csv files\n",
    "\n",
    "The output of evaluation(mode=0) returns:\n",
    "* (x1, x2) which referes to the expression of receptor and ligand\n",
    "* (y) if the label (positive/negative), which is used for evaluation and calculating the accuracy and F1-score\n",
    "* (x1id, x2id) are the corresponding index in the csv files\n",
    "\n",
    "The output of prediction(mode=2) returns:\n",
    "* (x1, x2) refers to the expression of receptor and ligand\n",
    "* (x1id, x2id) are the corresponding index in the csv files\n",
    "\n",
    "The difference between prediction mode (mode=2) and evaluation(mode=0) is if ground truth labels exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a48d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(cfg, train=1):\n",
    "    if train == 1:\n",
    "        root = cfg['DATASET']['TRAIN_ROOT']\n",
    "    elif train == 0:\n",
    "        root = cfg['DATASET']['TEST_ROOT']\n",
    "    elif train == 2:\n",
    "        root = cfg['DATASET']['PRED_ROOT']\n",
    "\n",
    "    if cfg['DATASET']['NAME'] == 'TripletData':\n",
    "        dataset = TripletData(istrain=train,\n",
    "                              dataroot=root,\n",
    "                              matrixroot=cfg['DATASET']['MATRIX_ROOT'])\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e90dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(cfg, train=1)\n",
    "\n",
    "train_dataloader = Data.DataLoader(train_dataset,\n",
    "                                batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b17927",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = build_dataset(cfg, train=0)\n",
    "\n",
    "test_dataloader = Data.DataLoader(test_dataset,\n",
    "                                batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e30d38",
   "metadata": {},
   "source": [
    "### 4.1 Load spatial graph \n",
    "In spaCI, the spatial graph is calculated by cell locations and saved in the format of csv files.\n",
    "Please refer to the pre-processing manual [here](https://github.com/tonyyang1995/spaCI/blob/main/README.md) to generate spatial graph for your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c63714",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = pd.read_csv(cfg['DATASET']['ADJ_ROOT'], header=0, index_col=0)\n",
    "adj = torch.from_numpy(adj.to_numpy()).float()\n",
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a052587",
   "metadata": {},
   "source": [
    "### 5. Run spaCI\n",
    "The configuration ymal file is provided for users to set model parameters.\n",
    "* INPUT_DIM: the number of genes in your dataset. This is the input of MLP trunk. In this demo, the dimension is 4000\n",
    "* GRAPH_DIM: the number of genes in your dataset. This is the input of Graph trunk. In this demo, the dimension is 4000\n",
    "* MlP_HID_DIMs: the hidden dimensions of MLP layers\n",
    "* GRAPH_HID_DIMS: the hidden dimensions of graph layers\n",
    "* SAVE_PATH: the folder path of saved checkpoint\n",
    "* TripletGraphModel: spaCI model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa11c02",
   "metadata": {},
   "source": [
    "### 5.1 Parameter tuning\n",
    "We provide one-command bash script for parameter tuning in spaCI, which shows the best parameters for spatial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bash parameter_tuning.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2200ee",
   "metadata": {},
   "source": [
    "### 5.2 Train spaCI\n",
    "Below shows the codes for training spaCI. Here you can customize your own epochs in the yaml files.\n",
    "  In this toy demo, epochs=10 or epochs=20 is enough.\n",
    "  We evaluate the model performance in every epoch, and save model parameters with the best f1 scores.\n",
    "  Note that we only validate on validation set, which is not used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff940c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [01:09<00:00,  6.95s/it]\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "for epoch in tqdm(range(cfg['TRAIN']['EPOCHS'])):\n",
    "    # train\n",
    "    for batch, (a, p, n, aid, pid, nid) in enumerate(train_dataloader):\n",
    "        inputs = {}\n",
    "        inputs['A'] = a; inputs['P'] = p; inputs['N'] = n\n",
    "            \n",
    "        inputs['adj'] = adj\n",
    "        model.set_input(inputs, istrain=1)\n",
    "        model.single_update()\n",
    "    \n",
    "    f1 = infer(model, cfg, verbose=False)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_epoch = epoch\n",
    "        model.save('best_f1')\n",
    "model.save('final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e38b5",
   "metadata": {},
   "source": [
    "### 5.3 Show evaluation results on validation set\n",
    "After training spaCI, the performance of the final model will be print with metrics as below:\n",
    "* accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* Specificity\n",
    "* Sensitivity\n",
    "* F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2710d7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------results----------------------\n",
      "       112\t       123\n",
      "       977\t       981\n",
      "      acc:\t    0.9864\n",
      "precision:\t    0.9655\n",
      "   recall:\t    0.9106\n",
      "Specificity:\t    0.9959\n",
      "Sensitivity:\t    0.9106\n",
      "F1-measure:\t    0.9372\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1 = infer(model, cfg, load_model='best_f1', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3746bcb4",
   "metadata": {},
   "source": [
    "### 5.4 Inference\n",
    "* Infer is used to evaluate the performance of spaCI and identify the best model on validation set. When \"load_model\" was not assign, or is None, we will use the default parameters in the pre-defined \"model\" object. Otherwise, we will load the saved checkpoint from disk.\n",
    "* verbose is used to print the evaluation results. If verbose=True, the performance of current model in validation set will be print.\n",
    "\n",
    "Note that we divided the train/val set. The inference can be used to evaluate the model performance and help us to find the model with best F1-score. You can consider this as a trick for early stop/find best model strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f063321",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(model, cfg, load_model=None, verbose=False):\n",
    "    seed = 10\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    dataset = build_dataset(cfg, train=0)\n",
    "    dataloader = Data.DataLoader(dataset,\n",
    "                                 batch_size=cfg['TEST']['BATCH_SIZE'],\n",
    "                                 shuffle=False)\n",
    "    if load_model is not None:\n",
    "        model_path = os.path.join(cfg['MODEL']['SAVE_PATH'],\n",
    "                                  load_model + '.pth')\n",
    "        model.load(model_path)\n",
    "\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    label_tp = 0\n",
    "    label_tn = 0\n",
    "\n",
    "    # check dirs\n",
    "    dirs = cfg['TEST']['PRED']\n",
    "    dirs = dirs.split('/')[:-1]\n",
    "    dirs = '/'.join(dirs)\n",
    "    if not os.path.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "    \n",
    "    savepred = open(cfg['TEST']['PRED'], 'w')\n",
    "    savepred.write('ligand,receptor,truelabel,pred\\n')\n",
    "    adj = pd.read_csv(cfg['DATASET']['ADJ_ROOT'], header=0, index_col=0)\n",
    "    adj = torch.from_numpy(adj.to_numpy()).float()\n",
    "\n",
    "    for batch, (x1, x2, y, x1id, x2id) in enumerate(dataloader):\n",
    "        inputs = {}\n",
    "        inputs['x1'] = x1\n",
    "        inputs['x2'] = x2\n",
    "        inputs['label'] = y\n",
    "        inputs['adj'] = adj\n",
    "        threshold = cfg['TEST']['THRESHOLD']\n",
    "\n",
    "        model.set_input(inputs, istrain=0)\n",
    "        dis = model.inference()\n",
    "        # print(pred.shape, y.shape)\n",
    "        dis = dis.detach().cpu()\n",
    "\n",
    "        pred = torch.zeros(dis.shape)\n",
    "        pred[dis > threshold] = 1\n",
    "\n",
    "        TP += ((pred == 1) & (y == 1)).sum()\n",
    "        TN += ((pred == 0) & (y == 0)).sum()\n",
    "        FP += ((pred == 1) & (y == 0)).sum()\n",
    "        FN += ((pred == 0) & (y == 1)).sum()\n",
    "        label_tp += (y == 1).sum()\n",
    "        label_tn += (y == 0).sum()\n",
    "\n",
    "        for i in range(len(x1id)):\n",
    "            id1, id2 = x1id[i], x2id[i]\n",
    "            savepred.write('%s,%s,%d,%d,%.4f\\n' %\n",
    "                           (id1, id2, y[i], int(pred[i]), dis[i]))\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "    sensitive = TP / (TP + FN) if (TP + FN) else 0\n",
    "    specity = TN / (TN + FP) if (TN + FP) else 0\n",
    "    acc = (TP + TN) / (label_tp + label_tn)\n",
    "    F1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    if verbose:\n",
    "        message = '\\n------------------------results----------------------\\n'\n",
    "        message += '{:>10d}\\t{:>10d}\\n'.format(TP, label_tp)\n",
    "        message += '{:>10d}\\t{:>10d}\\n'.format(TN, label_tn)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('acc:', acc)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('precision:', precision)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('recall:', recall)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('Specificity:', specity)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('Sensitivity:', sensitive)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('F1-measure:', F1)\n",
    "        message += '------------------------------------------------------\\n'\n",
    "        print(message)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b9216",
   "metadata": {},
   "source": [
    "### 5.5 Save L-R embeddings and predictions\n",
    "In this stage, L-R interactions are predictd and saved with their embeddings.\n",
    "  Since the model have been trained, and all the parameters are fixed, you can predict from multiple inputs, and and do some down-stream tasks based on the predictions or embeddings.\n",
    "  The predictions and embedding will be saved in the following path, and you can customize it from configure.yml.\n",
    "* L-R predictions will be saved in \"results/predict.csv\"\n",
    "* L-R embeddings will be saved in \"results/embed_ligand.csv\" and \"results/embed_receptor.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d8aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(cfg, load_model=None):\n",
    "    seed = 10\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    model = build_model(cfg)\n",
    "\n",
    "    dataset = build_dataset(cfg, train=2)\n",
    "    dataloader = Data.DataLoader(dataset,\n",
    "                                 batch_size=cfg['TEST']['BATCH_SIZE'],\n",
    "                                 shuffle=False)\n",
    "    if load_model is not None:\n",
    "        model_path = os.path.join(cfg['MODEL']['SAVE_PATH'],\n",
    "                                  load_model + '.pth')\n",
    "        model.load(model_path)\n",
    "\n",
    "    savepred = open(cfg['TEST']['PRED'], 'w')\n",
    "    savepred.write('ligand,receptor,truelabel,pred\\n')\n",
    "\n",
    "    adj = pd.read_csv(cfg['DATASET']['ADJ_ROOT'], header=0,\n",
    "                      index_col=0)  #, chunksize=1000)\n",
    "    adj = torch.from_numpy(adj.to_numpy()).float()\n",
    "    threshold = cfg['TEST']['THRESHOLD']\n",
    "\n",
    "    embs1 = None\n",
    "    embs2 = None\n",
    "    index1 = None\n",
    "    index2 = None\n",
    "\n",
    "    for batch, (x1, x2, x1id, x2id) in enumerate(dataloader):\n",
    "        inputs = {}\n",
    "        inputs['x1'] = x1\n",
    "        inputs['x2'] = x2\n",
    "#         inputs['label'] = y\n",
    "        inputs['adj'] = adj\n",
    "\n",
    "        model.set_input(inputs, istrain=0)\n",
    "        dis, emb1, emb2 = model.inference(return_intermediate=True)\n",
    "        # print(x1id, emb1.shape)\n",
    "        dis = dis.detach().cpu()\n",
    "        emb1 = emb1.detach().cpu().numpy()\n",
    "        emb2 = emb2.detach().cpu().numpy()\n",
    "\n",
    "        if embs1 is None:\n",
    "            embs1 = emb1\n",
    "            index1 = x1id\n",
    "        else:\n",
    "            embs1 = np.concatenate([embs1, emb1], axis=0)\n",
    "            index1 = np.concatenate([index1, x1id], axis=0)\n",
    "\n",
    "        if embs2 is None:\n",
    "            embs2 = emb2\n",
    "            index2 = x2id\n",
    "        else:\n",
    "            embs2 = np.concatenate([embs2, emb2], axis=0)\n",
    "            index2 = np.concatenate([index2, x2id], axis=0)\n",
    "\n",
    "        pred = torch.zeros(dis.shape)\n",
    "        pred[dis > threshold] = 1\n",
    "\n",
    "        for i in range(len(x1id)):\n",
    "            id1, id2 = x1id[i], x2id[i]\n",
    "            savepred.write('%s,%s,%d,%.4f\\n' %\n",
    "                           (id1, id2, int(pred[i]), dis[i]))\n",
    "        df1 = pd.DataFrame(embs1, index=index1)\n",
    "        df2 = pd.DataFrame(embs2, index=index2)\n",
    "        df1.to_csv(cfg['TEST']['EMB1'])\n",
    "        df2.to_csv(cfg['TEST']['EMB2'])\n",
    "\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc463004",
   "metadata": {},
   "source": [
    "The prediction function is shown below. When the prediction is completed, it will print \"done\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fd14d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "predict(cfg, load_model='best_f1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6410689e",
   "metadata": {},
   "source": [
    "### Configuration Tutorial\n",
    "\n",
    "The configure.yml look like the following:\n",
    "You can modify the hyper parameters to meet you own dataset, and build your own model\n",
    "```\n",
    "DATASET:\n",
    "  NAME: TripletData\n",
    "  TRAIN_ROOT: ../dataset/triplet.csv\n",
    "  TEST_ROOT: ../dataset/test_pairs.csv\n",
    "  PRED_ROOT: ../dataset/test_lr_pairs.csv\n",
    "  MATRIX_ROOT: ../dataset/exp_data_LR.csv\n",
    "  ADJ_ROOT: ../dataset/spatial_graph.csv\n",
    "MODEL:\n",
    "  NAME: TripletGraphModel\n",
    "  INPUT_DIM: 4000\n",
    "  GRAPH_DIM: 4000\n",
    "  MLP_HID_DIMS: [200,50,20]\n",
    "  GRAPH_HID_DIMS: [200,50,20]\n",
    "  SAVE_PATH: checkpoint/triplet/\n",
    "TRAIN:\n",
    "  LR: 0.000100\n",
    "  EPOCHS: 10\n",
    "  SAVE_PATH: checkpoint/triplet/\n",
    "  BATCH_SIZE: 2048\n",
    "TEST:\n",
    "  SAVE_PATH: checkpoint/triplet/best_f1.pth\n",
    "  BATCH_SIZE: 2048\n",
    "  PRED: results/predict.csv\n",
    "  EMB1: results/embed_ligand.csv\n",
    "  EMB2: results/embed_receptor.csv\n",
    "  THRESHOLD: 0.500000\n",
    "SEED: 10\n",
    "use_cuda: cuda:0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f78afe",
   "metadata": {},
   "source": [
    "Sometimes, we want to try different settings, and don't want to modify the configure.yml manually. Therefore, we provide a script for you, which can generate a configure using command lines. This is very useful when we tried to find the best hyper parameter combinations. The tutorial is like the following: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5545383f",
   "metadata": {},
   "source": [
    "We provided a python script named \"configuration.py\", which you can use to customize configuration for your own dataset. Details of the arguments are shown below:\n",
    "\n",
    "* --trainroot: a csv file with the (a, p, n) triplets. This is the defined triplet for training.\n",
    "* --testroot: a csv file with the ligand-receptor pairs, we have labels for validation. This is the defined LR pairs for validation. You need to provide labels in this csv file.\n",
    "* --predroot: a csv file to predict the whether a ligand-receptor pair is positive or not. We only have the data, without labels. This is the defined LR pairs for prediction. You don't need to provide labels in this csv file.\n",
    "* --input_dim: the input dimension for mlp trunk, which should be the dimension of gene expressions, unless you want to do some dimension reduction in your own settings.\n",
    "* --graph_dim: the input dimension for graph trunk, which should be the dimension of gene expression, unless you want to do some dimension reduction in your own settings.\n",
    "* --mlp_hid_dims: the hidden dimensions of mlp layers, you can customize your own MLP layers, with arbitrary dimensions for arbitrary number of layers.\n",
    "* --graph_hid_dims: the hidden dimensions of graph layers,  you can customize your own graph layers, with arbitrary dimensions for arbitrary number of layers.\n",
    "* --lr: the learning rate, this is the learning rate for SGD/Adam optimizer for training.\n",
    "* --epochs: the total rounds of training\n",
    "* --save_path: path for check points\n",
    "* --batch_size: the number of pairs for each batch\n",
    "* --test_save_path: the selected checkpoint path\n",
    "* --pred: the path for saving the prediction in the form of csv files.\n",
    "* --emb1: the path for saving embedings of ligand in the form of csv files.\n",
    "* --emb2: the path for saving embedings of receptor in the form of csv files.\n",
    "* --threshold: the threshold to determine whether a L-R pair is positive or not.\n",
    "* --seed: the fixed seed.\n",
    "* --ymlname: name of the configuration yaml file.\n",
    "* --use_cuda: defined whether you want to use gpu or not. You need to give the device id like \"cuda:0\" or \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271226c8",
   "metadata": {},
   "source": [
    "a demo usage will be:\n",
    "```\n",
    "python3 configuration.py --ymlname configure.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46517c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # dataset\n",
    "    parser.add_argument('--dataname', type=str, default='TripletData')\n",
    "    parser.add_argument('--trainroot', type=str, default='data_IO/triplet.csv')\n",
    "    parser.add_argument('--testroot', type=str, default='data_IO/test_pairs.csv')\n",
    "    parser.add_argument('--predroot', type=str, default='data_IO/test_lr_pairs.csv')\n",
    "    parser.add_argument('--matrixroot', type=str, default='data_IO/exp_data_LR.csv')\n",
    "    parser.add_argument('--adjroot', type=str, default='data_IO/spatial_graph.csv')\n",
    "\n",
    "    # model\n",
    "    parser.add_argument('--modelname', type=str, default='TripletGraphModel')\n",
    "    parser.add_argument('--input_dim', type=int, default=4000)\n",
    "    parser.add_argument('--graph_dim', type=int, default=4000)\n",
    "    parser.add_argument('--mlp_hid_dims', type=str, default='200,50,20')\n",
    "    parser.add_argument('--graph_hid_dims', type=str, default='200,50,20')\n",
    "    # parser.add_argument('--save_path', type=str, default='checkpoint/triplet/')\n",
    "\n",
    "    # train\n",
    "    parser.add_argument('--lr', type=float, default=1e-4)\n",
    "    parser.add_argument('--epochs', type=int, default=10)\n",
    "    parser.add_argument('--save_path', type=str, default='checkpoint/triplet/')\n",
    "    parser.add_argument('--batch_size', type=int, default=2048)\n",
    "\n",
    "    # test\n",
    "    parser.add_argument('--test_save_path', type=str, default='checkpoint/triplet/best_f1.pth')\n",
    "    # parser.add_argument('--batch_size', type=int, default=512)\n",
    "    parser.add_argument('--pred', type=str, default='results/predict.csv')\n",
    "    parser.add_argument('--emb1', type=str, default='results/embed_ligand.csv')\n",
    "    parser.add_argument('--emb2', type=str, default='results/embed_receptor.csv')\n",
    "    parser.add_argument('--threshold', type=float, default=0.5)\n",
    "\n",
    "    # seed\n",
    "    parser.add_argument('--seed', type=int, default=10)\n",
    "    \n",
    "    parser.add_argument('--use_cuda', type=str, default='cuda:0')\n",
    "\n",
    "    # yml name\n",
    "    parser.add_argument('--ymlname', type=str, default='configure_gen.yml')\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    yml = open(opt.ymlname, 'w')\n",
    "    yml.write('DATASET:\\n')\n",
    "    yml.write('  NAME: %s\\n'%(opt.dataname))\n",
    "    yml.write('  TRAIN_ROOT: %s\\n'%(opt.trainroot))\n",
    "    yml.write('  TEST_ROOT: %s\\n'%(opt.testroot))\n",
    "    yml.write('  PRED_ROOT: %s\\n'%(opt.predroot))\n",
    "    yml.write('  MATRIX_ROOT: %s\\n'%(opt.matrixroot))\n",
    "    yml.write('  ADJ_ROOT: %s\\n'%(opt.adjroot))\n",
    "\n",
    "    yml.write('MODEL:\\n')\n",
    "    yml.write('  NAME: %s\\n'%(opt.modelname))\n",
    "    yml.write('  INPUT_DIM: %d\\n'%(opt.input_dim))\n",
    "    yml.write('  GRAPH_DIM: %d\\n'%(opt.input_dim))\n",
    "\n",
    "    mlp_hid_dims = opt.mlp_hid_dims.split(',')\n",
    "    mlp_hid_dims = [int(x) for x in mlp_hid_dims]\n",
    "    yml.write('  MLP_HID_DIMS: [%d'%(mlp_hid_dims[0]))\n",
    "    for d in mlp_hid_dims[1:]:\n",
    "        yml.write(',%d'%(d))\n",
    "    yml.write(']\\n')\n",
    "\n",
    "    graph_hid_dims = opt.graph_hid_dims.split(',')\n",
    "    graph_hid_dims = [int(x) for x in graph_hid_dims]\n",
    "    yml.write('  GRAPH_HID_DIMS: [%d'%(graph_hid_dims[0]))\n",
    "    for d in graph_hid_dims[1:]:\n",
    "        yml.write(',%d'%(d))\n",
    "    yml.write(']\\n')\n",
    "    yml.write('  SAVE_PATH: %s\\n'%(opt.save_path))\n",
    "\n",
    "    yml.write('TRAIN:\\n')\n",
    "    yml.write('  LR: %f\\n'%(opt.lr))\n",
    "    yml.write('  EPOCHS: %d\\n'%(opt.epochs))\n",
    "    yml.write('  SAVE_PATH: %s\\n'%(opt.save_path))\n",
    "    yml.write('  BATCH_SIZE: %d\\n'%(opt.batch_size))\n",
    "\n",
    "    yml.write('TEST:\\n')\n",
    "    yml.write('  SAVE_PATH: %s\\n'%(opt.test_save_path))\n",
    "    yml.write('  BATCH_SIZE: %d\\n'%(opt.batch_size))\n",
    "    yml.write('  PRED: %s\\n'%(opt.pred))\n",
    "    yml.write('  EMB1: %s\\n'%(opt.emb1))\n",
    "    yml.write('  EMB2: %s\\n'%(opt.emb2))\n",
    "    yml.write('  THRESHOLD: %f\\n'%(opt.threshold))\n",
    "\n",
    "    yml.write('SEED: %d\\n'%(opt.seed))\n",
    "    yml.write('use_cuda: %s\\n'%(opt.use_cuda))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

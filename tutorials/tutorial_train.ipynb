{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70bea20",
   "metadata": {},
   "source": [
    "# SPACI tutorial\n",
    "\n",
    "## 1. import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f88d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import yaml\n",
    "from model.dataloader import TripletData\n",
    "from model.model import PairModel, TripletModel, TripletGraphModel\n",
    "import os\n",
    "import torch.utils.data as Data\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c5de5",
   "metadata": {},
   "source": [
    "### 1.1 load yaml configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e2ca435",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = 'configure_0.90.yml'\n",
    "with open(yaml_file) as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84510171",
   "metadata": {},
   "source": [
    "### 1.2 fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ae9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e698392a",
   "metadata": {},
   "source": [
    "### 2. build dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a48d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(cfg, train=1):\n",
    "    if train == 1:\n",
    "        root = cfg['DATASET']['TRAIN_ROOT']\n",
    "    elif train == 0:\n",
    "        root = cfg['DATASET']['TEST_ROOT']\n",
    "    elif train == 2:\n",
    "        root = cfg['DATASET']['PRED_ROOT']\n",
    "\n",
    "    if cfg['DATASET']['NAME'] == 'TripletData':\n",
    "        dataset = TripletData(istrain=train,\n",
    "                              dataroot=root,\n",
    "                              matrixroot=cfg['DATASET']['MATRIX_ROOT'])\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade810e",
   "metadata": {},
   "source": [
    "### 2.1 build train_dataset and test dataset\n",
    "We set up three different modes (mode=0, 1, 2) when building the dataset\n",
    "1. mode=1 for training. In training mode\n",
    "2. mode=2 for evaluate the f1 scores\n",
    "3. mode=3 for prediction and save the embeddings and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e90dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(cfg, train=1)\n",
    "\n",
    "train_dataloader = Data.DataLoader(train_dataset,\n",
    "                                batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b17927",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = build_dataset(cfg, train=0)\n",
    "\n",
    "test_dataloader = Data.DataLoader(test_dataset,\n",
    "                                batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e30d38",
   "metadata": {},
   "source": [
    "### 2.2 Load spatial graph \n",
    "we processed the graph in the form of adjacent list, saving in csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c63714",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = pd.read_csv(cfg['DATASET']['ADJ_ROOT'], header=0, index_col=0)\n",
    "adj = torch.from_numpy(adj.to_numpy()).float()\n",
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a052587",
   "metadata": {},
   "source": [
    "### 3. build model\n",
    "We provided an interface in the yaml file for end-users to build up their own model structures.\n",
    "1. Input Dim is the number of genes in your dataset. This is the input of MLP trunk. In this demo, the dimension is 4000\n",
    "2. Graph Dim is the number of genes in your dataset. This is the input of Graph trunk. In this demo, the dimension is 4000\n",
    "3. Mlp_hid_dim is the hidden dimensions of the MLP layers\n",
    "4. Graph_hid_dim is the hidden dimensions of the Graph layers\n",
    "5. save_path is the dir of save the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b686f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cfg):\n",
    "    lr = float(cfg['TRAIN']['LR'])\n",
    "    if cfg['MODEL']['NAME'] == 'TripletGraphModel':\n",
    "        model = TripletGraphModel(\n",
    "            lr=lr,\n",
    "            input_dim=cfg['MODEL']['INPUT_DIM'],\n",
    "            graph_dim=cfg['MODEL']['GRAPH_DIM'],\n",
    "            mlp_channels=cfg['MODEL']['MLP_HID_DIMS'],\n",
    "            graph_channels=cfg['MODEL']['GRAPH_HID_DIMS'],\n",
    "            save_path=cfg['MODEL']['SAVE_PATH'])\n",
    "        return model\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "799385f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a77e07",
   "metadata": {},
   "source": [
    "### train and select best f1\n",
    "### 3.1 inference\n",
    "we first define the train/inference/prediction of spaci. \n",
    "1. Infer was used to evaluate the performance of spaci. When \"load_model\" was not assign, or is None, we will use the default parameters in the pre-defined \"model\" object. Otherwise, we will load the saved checkpoint from disk.\n",
    "2. verbose was used to print the evaluation results. When verbose=True, we will print the performance of current model in validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b67a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(model, cfg, load_model=None, verbose=False):\n",
    "    seed = 10\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    dataset = build_dataset(cfg, train=0)\n",
    "    dataloader = Data.DataLoader(dataset,\n",
    "                                 batch_size=cfg['TEST']['BATCH_SIZE'],\n",
    "                                 shuffle=False)\n",
    "    if load_model is not None:\n",
    "        model_path = os.path.join(cfg['MODEL']['SAVE_PATH'],\n",
    "                                  load_model + '.pth')\n",
    "        model.load(model_path)\n",
    "\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    label_tp = 0\n",
    "    label_tn = 0\n",
    "\n",
    "    savepred = open(cfg['TEST']['PRED'], 'w')\n",
    "    savepred.write('ligand,receptor,truelabel,pred\\n')\n",
    "    adj = pd.read_csv(cfg['DATASET']['ADJ_ROOT'], header=0, index_col=0)\n",
    "    adj = torch.from_numpy(adj.to_numpy()).float()\n",
    "\n",
    "    for batch, (x1, x2, y, x1id, x2id) in enumerate(dataloader):\n",
    "        inputs = {}\n",
    "        inputs['x1'] = x1\n",
    "        inputs['x2'] = x2\n",
    "        inputs['label'] = y\n",
    "        inputs['adj'] = adj\n",
    "        threshold = cfg['TEST']['THRESHOLD']\n",
    "\n",
    "        model.set_input(inputs, istrain=0)\n",
    "        dis = model.inference()\n",
    "        # print(pred.shape, y.shape)\n",
    "        dis = dis.detach().cpu()\n",
    "\n",
    "        pred = torch.zeros(dis.shape)\n",
    "        pred[dis > threshold] = 1\n",
    "\n",
    "        TP += ((pred == 1) & (y == 1)).sum()\n",
    "        TN += ((pred == 0) & (y == 0)).sum()\n",
    "        FP += ((pred == 1) & (y == 0)).sum()\n",
    "        FN += ((pred == 0) & (y == 1)).sum()\n",
    "        label_tp += (y == 1).sum()\n",
    "        label_tn += (y == 0).sum()\n",
    "\n",
    "        for i in range(len(x1id)):\n",
    "            id1, id2 = x1id[i], x2id[i]\n",
    "            savepred.write('%s,%s,%d,%d,%.4f\\n' %\n",
    "                           (id1, id2, y[i], int(pred[i]), dis[i]))\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "    sensitive = TP / (TP + FN) if (TP + FN) else 0\n",
    "    specity = TN / (TN + FP) if (TN + FP) else 0\n",
    "    acc = (TP + TN) / (label_tp + label_tn)\n",
    "    F1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    if verbose:\n",
    "        message = '\\n------------------------results----------------------\\n'\n",
    "        message += '{:>10d}\\t{:>10d}\\n'.format(TP, label_tp)\n",
    "        message += '{:>10d}\\t{:>10d}\\n'.format(TN, label_tn)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('acc:', acc)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('precision:', precision)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('recall:', recall)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('Specificity:', specity)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('Sensitivity:', sensitive)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('F1-measure:', F1)\n",
    "        message += '------------------------------------------------------\\n'\n",
    "        print(message)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2200ee",
   "metadata": {},
   "source": [
    "### 3.2 train spaci\n",
    "we evaluate the performance of each epoch, and saved the model with best f1 scores as our final checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ff940c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10/10 [05:30<00:00, 33.02s/it]\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "for epoch in tqdm(range(cfg['TRAIN']['EPOCHS'])):\n",
    "    # train\n",
    "    for batch, (a, p, n, aid, pid, nid) in enumerate(train_dataloader):\n",
    "        inputs = {}\n",
    "        inputs['A'] = a; inputs['P'] = p; inputs['N'] = n\n",
    "            \n",
    "        inputs['adj'] = adj\n",
    "        model.set_input(inputs, istrain=1)\n",
    "        model.single_update()\n",
    "    \n",
    "    f1 = infer(model, cfg, verbose=False)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_epoch = epoch\n",
    "        model.save('best_f1')\n",
    "model.save('final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e38b5",
   "metadata": {},
   "source": [
    "### 3.3 show evaluation results\n",
    "after training spaci, we print the performance of the model.\n",
    "We will show:\n",
    "1. accuracy\n",
    "2. Precision\n",
    "3. Recall\n",
    "4. Specificity\n",
    "5. Sensitivity\n",
    "6. F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2710d7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------results----------------------\n",
      "       103\t       123\n",
      "       980\t       981\n",
      "      acc:\t    0.9810\n",
      "precision:\t    0.9904\n",
      "   recall:\t    0.8374\n",
      "Specificity:\t    0.9990\n",
      "Sensitivity:\t    0.8374\n",
      "F1-measure:\t    0.9075\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1 = infer(model, cfg, load_model='best_f1', verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b9216",
   "metadata": {},
   "source": [
    "### 3.4 saved the embeddings and predictions\n",
    "1. the prediction will be saved in \"results/predict.csv\"\n",
    "2. The embeddings will be saved in \"results/embed_ligand.csv\" and \"results/embed_receptor.csv\"\n",
    "3. We set up the threshold as 0.9. Which means, a larger cos-similarity of ligand-receptor pair score (>0.9) will be considered as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1d8aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(cfg, load_model=None):\n",
    "    seed = 10\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    model = build_model(cfg)\n",
    "\n",
    "    dataset = build_dataset(cfg, train=2)\n",
    "    dataloader = Data.DataLoader(dataset,\n",
    "                                 batch_size=cfg['TEST']['BATCH_SIZE'],\n",
    "                                 shuffle=False)\n",
    "    if load_model is not None:\n",
    "        model_path = os.path.join(cfg['MODEL']['SAVE_PATH'],\n",
    "                                  load_model + '.pth')\n",
    "        model.load(model_path)\n",
    "\n",
    "    savepred = open(cfg['TEST']['PRED'], 'w')\n",
    "    savepred.write('ligand,receptor,truelabel,pred\\n')\n",
    "\n",
    "    adj = pd.read_csv(cfg['DATASET']['ADJ_ROOT'], header=0,\n",
    "                      index_col=0)  #, chunksize=1000)\n",
    "    adj = torch.from_numpy(adj.to_numpy()).float()\n",
    "    threshold = cfg['TEST']['THRESHOLD']\n",
    "\n",
    "    embs1 = None\n",
    "    embs2 = None\n",
    "    index1 = None\n",
    "    index2 = None\n",
    "\n",
    "    for batch, (x1, x2, y, x1id, x2id) in enumerate(dataloader):\n",
    "        inputs = {}\n",
    "        inputs['x1'] = x1\n",
    "        inputs['x2'] = x2\n",
    "        inputs['label'] = y\n",
    "        inputs['adj'] = adj\n",
    "\n",
    "        model.set_input(inputs, istrain=0)\n",
    "        dis, emb1, emb2 = model.inference(return_intermediate=True)\n",
    "        # print(x1id, emb1.shape)\n",
    "        dis = dis.detach().cpu()\n",
    "        emb1 = emb1.detach().cpu().numpy()\n",
    "        emb2 = emb2.detach().cpu().numpy()\n",
    "\n",
    "        if embs1 is None:\n",
    "            embs1 = emb1\n",
    "            index1 = x1id\n",
    "        else:\n",
    "            embs1 = np.concatenate([embs1, emb1], axis=0)\n",
    "            index1 = np.concatenate([index1, x1id], axis=0)\n",
    "\n",
    "        if embs2 is None:\n",
    "            embs2 = emb2\n",
    "            index2 = x2id\n",
    "        else:\n",
    "            embs2 = np.concatenate([embs2, emb2], axis=0)\n",
    "            index2 = np.concatenate([index2, x2id], axis=0)\n",
    "\n",
    "        pred = torch.zeros(dis.shape)\n",
    "        pred[dis > threshold] = 1\n",
    "\n",
    "        for i in range(len(x1id)):\n",
    "            id1, id2 = x1id[i], x2id[i]\n",
    "            savepred.write('%s,%s,%d,%d,%.4f\\n' %\n",
    "                           (id1, id2, y[i], int(pred[i]), dis[i]))\n",
    "        df1 = pd.DataFrame(embs1, index=index1)\n",
    "        df2 = pd.DataFrame(embs2, index=index2)\n",
    "        df1.to_csv(cfg['TEST']['EMB1'])\n",
    "        df2.to_csv(cfg['TEST']['EMB2'])\n",
    "\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fd14d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "predict(cfg, load_model='best_f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1fb88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

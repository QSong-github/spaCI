{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70bea20",
   "metadata": {},
   "source": [
    "# spaCI tutorial\n",
    "Here we show how to use SpaCI to train, validate and predict the results.\n",
    "  Before this tutorial, you have already process the data, and put them in the corresponding dirs. Note that you can assign the data path in the configure.yml files.\n",
    "  Please refer to our preprocessing tutorail [here](https://github.com/tonyyang1995/spaCI/blob/main/README.md). You can find the precessing commands in FAQ.\n",
    "  In this tutorail, we will show you how to run spaCI step by step:\n",
    "1. import python modules\n",
    "2. load configurations\n",
    "3. fix seed\n",
    "4. build dataloader\n",
    "5. build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb405989",
   "metadata": {},
   "source": [
    "### 1. import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f88d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "# insert the parent dir into the path\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import yaml\n",
    "from model.dataloader import TripletData\n",
    "from model.model import TripletGraphModel\n",
    "import os\n",
    "import torch.utils.data as Data\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c5de5",
   "metadata": {},
   "source": [
    "### 2 load configurations\n",
    "In the configure.yml, you will define the model structure, and assign hypter-parameters for training\n",
    "You can also generate the configure.yml using the following scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f20e341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = 'python ../configuration.py --trainroot ../dataset/triplet.csv --testroot ../dataset/test_pairs.csv --predroot ../dataset/test_lr_pairs.csv --matrixroot ../dataset/exp_data_LR.csv --adjroot ../dataset/spatial_graph.csv --ymlname ../configure.yml --threshold 0.9'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2ca435",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = '../configure.yml'\n",
    "with open(yaml_file) as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84510171",
   "metadata": {},
   "source": [
    "### 3 Fix seed\n",
    "We fix all the seeds to reproducibility.\n",
    "When we are using GPUs, we need to fix cuda, which is:\n",
    "```\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "```\n",
    "If you are using cpus, you can comment the above mention lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ae9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e698392a",
   "metadata": {},
   "source": [
    "### 4. Build dataloader\n",
    "We set up three different modes (mode=0, 1, 2) when building the dataset\n",
    "1. mode=1 for training. In training mode\n",
    "2. mode=0 for evaluate the f1 scores\n",
    "3. mode=2 for prediction and save the embeddings and predictions\n",
    "\n",
    "Note that the output of training(mode=1) returns:\n",
    "* (a, p, n) which refers to the triplet anchor, positive and negative pairs\n",
    "* (aid, pid, nid) are the corresponding index in the csv files\n",
    "\n",
    "The output of evaluation(mode=0) returns:\n",
    "* (x1, x2) which referes to the expression of receptor and ligand\n",
    "* (y) if the label (positive/negative), which is used in evaluation and calculating the accuracy and F1-scores\n",
    "* (x1id, x2id) are the corresponding index in the csv files\n",
    "\n",
    "The output of prediction(mode=2) returns:\n",
    "* (x1, x2) which referes to the expression of receptor and ligand\n",
    "* (x1id, x2id) are the corresponding index in the csv files\n",
    "\n",
    "The difference between prediction mode (mode=2) and evaluation(mode=0) is the existence of labels.\n",
    "  We assume in prediction, we don't know the labels, so we didn't provide an interface to load the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a48d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(cfg, train=1):\n",
    "    if train == 1:\n",
    "        root = cfg['DATASET']['TRAIN_ROOT']\n",
    "    elif train == 0:\n",
    "        root = cfg['DATASET']['TEST_ROOT']\n",
    "    elif train == 2:\n",
    "        root = cfg['DATASET']['PRED_ROOT']\n",
    "\n",
    "    if cfg['DATASET']['NAME'] == 'TripletData':\n",
    "        dataset = TripletData(istrain=train,\n",
    "                              dataroot=root,\n",
    "                              matrixroot=cfg['DATASET']['MATRIX_ROOT'])\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e90dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(cfg, train=1)\n",
    "\n",
    "train_dataloader = Data.DataLoader(train_dataset,\n",
    "                                batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b17927",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = build_dataset(cfg, train=0)\n",
    "\n",
    "test_dataloader = Data.DataLoader(test_dataset,\n",
    "                                batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e30d38",
   "metadata": {},
   "source": [
    "### 4.1 Load spatial graph \n",
    "In SpaCI, we pre-compute the graph and saved spatial graph in the form of csv files.\n",
    "Please refer to the pre-processing manual [here](https://github.com/tonyyang1995/spaCI/blob/main/README.md) if you didn't generate the spatial graph.\n",
    "  Meanwhile, you can also build your own graph, just make sure using the same format in our settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c63714",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = pd.read_csv(cfg['DATASET']['ADJ_ROOT'], header=0, index_col=0)\n",
    "adj = torch.from_numpy(adj.to_numpy()).float()\n",
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a052587",
   "metadata": {},
   "source": [
    "### 5. Build model\n",
    "We provided an interface in the yaml file for end-users to build up their own model structures.\n",
    "* Input_Dim is the number of genes in your dataset. This is the input of MLP trunk. In this demo, the dimension is 4000\n",
    "* Graph_Dim is the number of genes in your dataset. This is the input of Graph trunk. In this demo, the dimension is 4000\n",
    "* Mlp_HID_DIMs is the hidden dimensions of the MLP layers\n",
    "* Graph_HID_DIMS is the hidden dimensions of the Graph layers\n",
    "* save_path is the dir of save the checkpoints\n",
    "\n",
    "In our early stage of this research, we also explore different models structure, for example: \n",
    "* TripletModel: which only implement the MLP trunk without graphs\n",
    "* PairModel: (didn't work), we tried to combine the two pairs (receptor-ligand) using concat style and forward with a MLP trunk. \n",
    "Please feel free to try these models if you are interested. But we recommand to use our proposed TripletGraphModel to reproduce the results in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8b686f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cfg):\n",
    "    lr = float(cfg['TRAIN']['LR'])\n",
    "    if cfg['MODEL']['NAME'] == 'TripletGraphModel':\n",
    "        model = TripletGraphModel(\n",
    "            lr=lr,\n",
    "            input_dim=cfg['MODEL']['INPUT_DIM'],\n",
    "            graph_dim=cfg['MODEL']['GRAPH_DIM'],\n",
    "            mlp_channels=cfg['MODEL']['MLP_HID_DIMS'],\n",
    "            graph_channels=cfg['MODEL']['GRAPH_HID_DIMS'],\n",
    "            save_path=cfg['MODEL']['SAVE_PATH'],\n",
    "            device=cfg['use_cuda'])\n",
    "        return model\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "799385f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a77e07",
   "metadata": {},
   "source": [
    "### 5.1 inference\n",
    "* Infer is used to evaluate the performance of spaCI and identify the best model on validation set. When \"load_model\" was not assign, or is None, we will use the default parameters in the pre-defined \"model\" object. Otherwise, we will load the saved checkpoint from disk.\n",
    "* verbose is used to print the evaluation results. If verbose=True, the performance of current model in validation set will be print.\n",
    "\n",
    "Note that we divided the train/val set. The inference can be used to evaluate the model performance and help us to find the model with best F1-score. You can consider this as a trick for early stop/find best model strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b67a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(model, cfg, load_model=None, verbose=False):\n",
    "    seed = 10\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    dataset = build_dataset(cfg, train=0)\n",
    "    dataloader = Data.DataLoader(dataset,\n",
    "                                 batch_size=cfg['TEST']['BATCH_SIZE'],\n",
    "                                 shuffle=False)\n",
    "    if load_model is not None:\n",
    "        model_path = os.path.join(cfg['MODEL']['SAVE_PATH'],\n",
    "                                  load_model + '.pth')\n",
    "        model.load(model_path)\n",
    "\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    label_tp = 0\n",
    "    label_tn = 0\n",
    "\n",
    "    # check dirs\n",
    "    dirs = cfg['TEST']['PRED']\n",
    "    dirs = dirs.split('/')[:-1]\n",
    "    dirs = '/'.join(dirs)\n",
    "    if not os.path.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "    \n",
    "    savepred = open(cfg['TEST']['PRED'], 'w')\n",
    "    savepred.write('ligand,receptor,truelabel,pred\\n')\n",
    "    adj = pd.read_csv(cfg['DATASET']['ADJ_ROOT'], header=0, index_col=0)\n",
    "    adj = torch.from_numpy(adj.to_numpy()).float()\n",
    "\n",
    "    for batch, (x1, x2, y, x1id, x2id) in enumerate(dataloader):\n",
    "        inputs = {}\n",
    "        inputs['x1'] = x1\n",
    "        inputs['x2'] = x2\n",
    "        inputs['label'] = y\n",
    "        inputs['adj'] = adj\n",
    "        threshold = cfg['TEST']['THRESHOLD']\n",
    "\n",
    "        model.set_input(inputs, istrain=0)\n",
    "        dis = model.inference()\n",
    "        # print(pred.shape, y.shape)\n",
    "        dis = dis.detach().cpu()\n",
    "\n",
    "        pred = torch.zeros(dis.shape)\n",
    "        pred[dis > threshold] = 1\n",
    "\n",
    "        TP += ((pred == 1) & (y == 1)).sum()\n",
    "        TN += ((pred == 0) & (y == 0)).sum()\n",
    "        FP += ((pred == 1) & (y == 0)).sum()\n",
    "        FN += ((pred == 0) & (y == 1)).sum()\n",
    "        label_tp += (y == 1).sum()\n",
    "        label_tn += (y == 0).sum()\n",
    "\n",
    "        for i in range(len(x1id)):\n",
    "            id1, id2 = x1id[i], x2id[i]\n",
    "            savepred.write('%s,%s,%d,%d,%.4f\\n' %\n",
    "                           (id1, id2, y[i], int(pred[i]), dis[i]))\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "    sensitive = TP / (TP + FN) if (TP + FN) else 0\n",
    "    specity = TN / (TN + FP) if (TN + FP) else 0\n",
    "    acc = (TP + TN) / (label_tp + label_tn)\n",
    "    F1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    if verbose:\n",
    "        message = '\\n------------------------results----------------------\\n'\n",
    "        message += '{:>10d}\\t{:>10d}\\n'.format(TP, label_tp)\n",
    "        message += '{:>10d}\\t{:>10d}\\n'.format(TN, label_tn)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('acc:', acc)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('precision:', precision)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('recall:', recall)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('Specificity:', specity)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('Sensitivity:', sensitive)\n",
    "        message += '{:>10}\\t{:>10.4f}\\n'.format('F1-measure:', F1)\n",
    "        message += '------------------------------------------------------\\n'\n",
    "        print(message)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2200ee",
   "metadata": {},
   "source": [
    "### 5.2 Train spaCI\n",
    "This is the code to train SpaCI. Here you can customize your own epochs in the yaml files.\n",
    "  In this toy demo, epochs=10 or epochs=20 is more than enough.\n",
    "  We evaluate the model performance in every epoch, and save the model parameters with the best f1 scores.\n",
    "  Note that we only validate on test set, and those data were not used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff940c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [01:09<00:00,  6.95s/it]\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "for epoch in tqdm(range(cfg['TRAIN']['EPOCHS'])):\n",
    "    # train\n",
    "    for batch, (a, p, n, aid, pid, nid) in enumerate(train_dataloader):\n",
    "        inputs = {}\n",
    "        inputs['A'] = a; inputs['P'] = p; inputs['N'] = n\n",
    "            \n",
    "        inputs['adj'] = adj\n",
    "        model.set_input(inputs, istrain=1)\n",
    "        model.single_update()\n",
    "    \n",
    "    f1 = infer(model, cfg, verbose=False)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_epoch = epoch\n",
    "        model.save('best_f1')\n",
    "model.save('final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e38b5",
   "metadata": {},
   "source": [
    "### 5.3 Show evaluation results\n",
    "After training spaCI, the performance of the final model will be print with metrics as below:\n",
    "* accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* Specificity\n",
    "* Sensitivity\n",
    "* F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2710d7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------results----------------------\n",
      "       112\t       123\n",
      "       977\t       981\n",
      "      acc:\t    0.9864\n",
      "precision:\t    0.9655\n",
      "   recall:\t    0.9106\n",
      "Specificity:\t    0.9959\n",
      "Sensitivity:\t    0.9106\n",
      "F1-measure:\t    0.9372\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1 = infer(model, cfg, load_model='best_f1', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b9216",
   "metadata": {},
   "source": [
    "### 5.4 Save the embeddings and predictions\n",
    "In this stage, we predict and save the embeddings from the testing dataset.\n",
    "  Since the model have been trained, and all the parameters were fixed, you can predict from multiple inputs, and and do some down-stream tasks based on the predictions or embeddings.\n",
    "  The predictions and embedding will be saved in the following path, and you can customize it from configure.yml.\n",
    "* L-R predictions will be saved in \"results/spaCI_predict.csv\"\n",
    "* L-R embeddings will be saved in \"results/embed_ligand.csv\" and \"results/embed_receptor.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d8aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(cfg, load_model=None):\n",
    "    seed = 10\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    model = build_model(cfg)\n",
    "\n",
    "    dataset = build_dataset(cfg, train=2)\n",
    "    dataloader = Data.DataLoader(dataset,\n",
    "                                 batch_size=cfg['TEST']['BATCH_SIZE'],\n",
    "                                 shuffle=False)\n",
    "    if load_model is not None:\n",
    "        model_path = os.path.join(cfg['MODEL']['SAVE_PATH'],\n",
    "                                  load_model + '.pth')\n",
    "        model.load(model_path)\n",
    "\n",
    "    savepred = open(cfg['TEST']['PRED'], 'w')\n",
    "    savepred.write('ligand,receptor,truelabel,pred\\n')\n",
    "\n",
    "    adj = pd.read_csv(cfg['DATASET']['ADJ_ROOT'], header=0,\n",
    "                      index_col=0)  #, chunksize=1000)\n",
    "    adj = torch.from_numpy(adj.to_numpy()).float()\n",
    "    threshold = cfg['TEST']['THRESHOLD']\n",
    "\n",
    "    embs1 = None\n",
    "    embs2 = None\n",
    "    index1 = None\n",
    "    index2 = None\n",
    "\n",
    "    for batch, (x1, x2, x1id, x2id) in enumerate(dataloader):\n",
    "        inputs = {}\n",
    "        inputs['x1'] = x1\n",
    "        inputs['x2'] = x2\n",
    "#         inputs['label'] = y\n",
    "        inputs['adj'] = adj\n",
    "\n",
    "        model.set_input(inputs, istrain=0)\n",
    "        dis, emb1, emb2 = model.inference(return_intermediate=True)\n",
    "        # print(x1id, emb1.shape)\n",
    "        dis = dis.detach().cpu()\n",
    "        emb1 = emb1.detach().cpu().numpy()\n",
    "        emb2 = emb2.detach().cpu().numpy()\n",
    "\n",
    "        if embs1 is None:\n",
    "            embs1 = emb1\n",
    "            index1 = x1id\n",
    "        else:\n",
    "            embs1 = np.concatenate([embs1, emb1], axis=0)\n",
    "            index1 = np.concatenate([index1, x1id], axis=0)\n",
    "\n",
    "        if embs2 is None:\n",
    "            embs2 = emb2\n",
    "            index2 = x2id\n",
    "        else:\n",
    "            embs2 = np.concatenate([embs2, emb2], axis=0)\n",
    "            index2 = np.concatenate([index2, x2id], axis=0)\n",
    "\n",
    "        pred = torch.zeros(dis.shape)\n",
    "        pred[dis > threshold] = 1\n",
    "\n",
    "        for i in range(len(x1id)):\n",
    "            id1, id2 = x1id[i], x2id[i]\n",
    "            savepred.write('%s,%s,%d,%.4f\\n' %\n",
    "                           (id1, id2, int(pred[i]), dis[i]))\n",
    "        df1 = pd.DataFrame(embs1, index=index1)\n",
    "        df2 = pd.DataFrame(embs2, index=index2)\n",
    "        df1.to_csv(cfg['TEST']['EMB1'])\n",
    "        df2.to_csv(cfg['TEST']['EMB2'])\n",
    "\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc463004",
   "metadata": {},
   "source": [
    "We run prediction functions here. When the predict is completed, we will print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fd14d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "predict(cfg, load_model='best_f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e19ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
